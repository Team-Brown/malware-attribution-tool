import gensim
import pickle
import pandas as pd
import re
import numpy as np
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import matplotlib
matplotlib.use('TkAgg')
import matplotlib.pyplot as plt


def read_corpus(fname, tokens_only=False):
    with open(fname, encoding="iso-8859-1") as f:
        for i, line in enumerate(f):
            tokens = gensim.utils.simple_preprocess(line)
            if tokens_only:
                yield tokens
            else:
                # For training data, add tags
                yield gensim.models.doc2vec.TaggedDocument(tokens, [i])

train_corp_doc = open("malware/test_corp_doc.txt", "r")

train_corpus = list(read_corpus("malware/test_corp_doc.txt"))

test_corpus = list(read_corpus("malware/test_corp_doc.txt", tokens_only=True))

model = gensim.models.doc2vec.Doc2Vec.load("model")

ranks = []
second_ranks = []
for doc_id in range(len(train_corpus)):
    inferred_vector = model.infer_vector(train_corpus[doc_id].words)
    sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))
    
    rank = [docid for docid, sim in sims].index(doc_id)
    ranks.append(rank)
    second_ranks.append(sims[1])
    

# for doc_id in range(len(train_corpus)):
#     sample = ' '.join(train_corpus[sims[0][0]][0])
#     sample_key = sample[:50]
#     print("\n\n========== SAMPLE #"+str(doc_id)+ " ==========")
#     print(" name : "+test_corp_dict[sample_key]+"\n")
#     print(ranks[doc_id])
#     # print(second_ranks[doc_id])

# print(ranks)
# print(second_ranks)


# Pick a random document from the test corpus and infer a vector from the model
for doc_id in range(len(test_corpus)):
    inferred_vector = model.infer_vector(test_corpus[doc_id])
    sims_test = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))

    # Compare and print the most/median/least similar documents from the train corpus
    print('\n\nTest Document ({}): «{}»\n'.format(doc_id, (' '.join(test_corpus[doc_id])[:30]+"... ")))
    print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\n' % model)

    print(sims_test)

    # for label, index in [('MOST', 0), ('SECOND MOST', 1), ('MEDIAN', len(sims_test)//2), ('LEAST', len(sims_test) - 1)]:
        # sample = ' '.join(test_corpus[sims_test[index][0]])
        # sample_key = sample[:50]
        # sample_name = test_corp_dict[sample_key]

        # print(u'%s %s: «%s»\n' % (label, sims_test[index], sample_name))



kmeans_model = KMeans(n_clusters=5, init='k-means++', max_iter=100) 
X = kmeans_model.fit(model.docvecs.vectors_docs)
labels=kmeans_model.labels_.tolist()
print("\n***** LABELS/CLUSTERS ******")
print(labels)
l = kmeans_model.fit_predict(model.docvecs.vectors_docs)
pca = PCA(n_components=2).fit(model.docvecs.vectors_docs)
datapoint = pca.transform(model.docvecs.vectors_docs)

# matplotlib inline
plt.figure
label1 = ["#FFFF00", "#008000", "#0000FF", "#800080", "#C884A6"]
color = [label1[i] for i in labels]
plt.scatter(datapoint[:, 0], datapoint[:, 1], c=color)
centroids = kmeans_model.cluster_centers_
centroidpoint = pca.transform(centroids)
plt.scatter(centroidpoint[:, 0], centroidpoint[:, 1], marker="^", s=150, c="#000000")
plt.show()

train_corp_doc.close()
# test_corp_doc.close()